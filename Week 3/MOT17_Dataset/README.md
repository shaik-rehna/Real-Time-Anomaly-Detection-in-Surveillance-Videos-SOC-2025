**`IMPORTANT:`**  MOT17 is a large dataset. It takes time to download it. So pls try to download it as early as possible

* First download the zip file(5.5GB) from this kaggle link : [MOT17_Download](https://www.kaggle.com/datasets/wenhoujinjust/mot-17)
* Upload the zip file in your google drive and extract the files (Use Google Drive's "Open with" â†’ "Google Zip Extractor")
* Or u can first extract the files locally and upload them to the google drive
  
  > Try to download the dataset in a single go without any interruptions
  

---
* It is very important to understand the dataset we are working with

* Go through the below info about MOT17 dataset. Understand what it contains and how the data is structured

### **What is the MOT17 Dataset?**

The **MOT17 dataset** is a benchmark dataset used in the **Multiple Object Tracking (MOT)** research community. It is part of the **MOTChallenge**, which provides a standard for evaluating and comparing tracking algorithms. 

The **MOT17 (Multiple Object Tracking 2017)** dataset is designed to evaluate **pedestrian tracking** algorithms in real-world scenarios. It includes multiple video sequences with varying challenges such as:

* **Camera motion** (static and moving)
* **Occlusions**
* **Crowded scenes**
* **Varying lighting and weather conditions**

---

## Number of Sequences

* **Train set**: 7 sequences (each with 3 detector variants â†’ 21 folders)
* **Test set**: 7 sequences (also with 3 detector variants)

Total: 14 unique videos Ã— 3 detectors = **42 sequences**.

---

## Directory Structure

Once downloaded and extracted, the MOT17 dataset typically looks like this:

```
MOT17/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ MOT17-02-DPM/
â”‚   â”œâ”€â”€ MOT17-02-FRCNN/
â”‚   â”œâ”€â”€ MOT17-02-SDP/
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ MOT17-04-DPM/
â”‚   â”œâ”€â”€ MOT17-04-FRCNN/
â”‚   â”œâ”€â”€ MOT17-04-SDP/
â”‚   â”œâ”€â”€ ...
```

MOT17 provides each video sequence **with 3 sets of detections**, generated by:

1. **DPM**: Deformable Parts Model
2. **FRCNN**: Faster R-CNN
3. **SDP**: Scale-Dependent Pooling

These are **pre-run object detectors** that predict bounding boxes on every frame.
These detections are saved in `det/det.txt` 


Each sequence like `MOT17-02-DPM` has:

* Same video frames as `MOT17-02-FRCNN`
* But different detection results


#### Why include them?

Because **MOT17 is a tracking-by-detection benchmark**.

So it evaluates **only the tracking performance**, assuming the detections come from a fixed detector.
That way, multiple trackers can be fairly compared using the **same input detections**.

---

## Contents of Each Sequence Folder

Each sequence (e.g., `MOT17-02-FRCNN`) contains:

```
MOT17-02-FRCNN/
â”œâ”€â”€ img1/               # All video frames as images
â”œâ”€â”€ gt/                 # Ground truth annotations (only in train)
â”‚   â””â”€â”€ gt.txt
â”œâ”€â”€ det/                # Provided detections
â”‚   â””â”€â”€ det.txt
â””â”€â”€ seqinfo.ini         # Sequence info (frame rate, image size, etc.)
```

### `gt.txt` (only in training set)

Ground truth bounding boxes for each frame, in the format:

```
frame_id, identity_id, x, y, w, h, conf, class, visibility
```

* `frame_id`: Frame number
* `identity_id`: Unique ID for each pedestrian
* `(x, y, w, h)`: Bounding box coordinates
* `conf`: Confidence (set to 1 for ground truth)
* `class`: Class ID (1 for pedestrian)
* `visibility`: Portion of bounding box visible (0â€“1)

### `det.txt`

Detections provided by the detector. Same format, but no identity ID:

```
frame_id, -1, x, y, w, h, conf, -1, -1
```

### `seqinfo.ini`

Metadata about the sequence:

```ini
[Sequence]
name=MOT17-02-FRCNN
imDir=img1
frameRate=30
seqLength=600
imWidth=1920
imHeight=1080
```

---

## Evaluation Metrics

The MOT17 benchmark evaluates algorithms using standardized metrics:

* **MOTA** (Multiple Object Tracking Accuracy)
* **MOTP** (Precision)
* **ID Switches** (Number of times a tracked ID changes)
* **Fragmentation**
* **False Positives / Negatives**

---

## Use Cases

MOT17 is used in:

* **Pedestrian tracking** research
* **Deep learning models** for object tracking (e.g., DeepSORT, FairMOT)
* **Benchmarking real-time multi-object trackers**

---

## ðŸ”— Download & License

* Website: [https://motchallenge.net/data/MOT17/](https://motchallenge.net/data/MOT17/)
* License: Academic research only

---


| Feature            | Description                                            |
| ------------------ | ------------------------------------------------------ |
| Purpose            | Benchmark for pedestrian multi-object tracking         |
| Includes           | Videos, detections, ground truth                       |
| Sequences          | 14 total (7 train, 7 test), each with 3 detector types |
| Annotations        | Bounding boxes, IDs, visibility                        |
| Evaluation Metrics | MOTA, MOTP, ID switches, fragments, etc.               |

---



 
